{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f801689e-7ed6-4929-b0bc-47068b9e92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g_analiser import Grafem_Analiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89135fe1-de53-4a05-9560-20d33f48d8e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предложение №0\n",
      "['Лек', 'бук']=А\n",
      "['Лек', 'бук']=Именно\n",
      "['DEL', 'ТИР']=–\n",
      "['LeX', 'chr']=StrOka\n",
      "['чис']=1\n",
      "['E_DEL', 'ЗПТ']=,\n",
      "['DEL', 'ТЧК']=.\n",
      "['лек', 'бук']=о\n",
      "['E_DEL', 'ЗПТ']=,\n",
      "['СОК', 'N_END', 'M_PST', 'FILE']=адм.-терр\n",
      "['E_DEL', 'ТЧК']=.\n",
      "['SKO', 'КАВ']=\"\n",
      "['B_SKO', 'О_СКБ']=(\n",
      "['B_SKO', 'О_ДКВ']=«\n",
      "['лек', 'бук']=со\n",
      "['лек', 'бук']=скобками\n",
      "['E_DEL', 'ТЧК']=.\n",
      "['E_SKO', 'З_ДКВ']=»\n",
      "['E_SKO', 'З_СКБ']=)\n",
      "['лек', 'бук']=и\n",
      "['СОК', 'M_END', 'N_PST', 'FILE']=т. д\n",
      "['E_DEL', 'ТЧК']=.\n"
     ]
    }
   ],
   "source": [
    "st = \"А Именно – StrOka 1, . о, адм.-терр. \\\" («со скобками.») и т. д.\"\n",
    "tokenizer = Grafem_Analiser()\n",
    "# processing\n",
    "tokenizer.process_(st)\n",
    "# postprocessing\n",
    "tokenizer.postProcess()\n",
    "for i in range(len(tokenizer.Promts)):\n",
    "            print(\"Предложение №%s\" % i)\n",
    "            for ii in range (len(tokenizer.Promts[i].Grafems)):\n",
    "                print(\"{}={}\".format(tokenizer.Promts[i].Grafems[ii].tip,\n",
    "                                     tokenizer.Promts[i].Grafems[ii].txt))\n",
    "# все графемы с тегами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a4c562-dfba-451a-b324-15aa85684e66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Настоящее Техническое задание составлено в соответствии с условиями Договора № 14-1 от 14 ноября 2003 г . и определяет форму и содержание работ , выполняемых исполнителем по Бланк–заказу . \n"
     ]
    }
   ],
   "source": [
    "text = \"Настоящее Техническое задание  составлено в соответствии с условиями Договора № 14-1 от 14 ноября 2003 г.  и определяет форму и содержание работ, выполняемых исполнителем по Бланк–заказу. Полнота реализации настоящего технического задания фиксируется Сторонами в акте приемки-сдачи.\"\n",
    "tokenizer.process_(text)\n",
    "tokenizer.postProcess()\n",
    "# первое предложение текста\n",
    "print(tokenizer.Promts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04f47e0-96d6-40fa-ac1a-102f1a02c6ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Виды\n",
      "лингвистического\n",
      "анализа\n",
      ":\n",
      "Учеб\n",
      ".\n",
      "пособие\n",
      "для\n",
      "студентов\n",
      "факультета\n",
      "русского\n",
      ".\n",
      "языка\n",
      ".\n",
      "и\n",
      "литературный\n",
      ".\n",
      "педагогический\n",
      ".\n",
      "институтов\n",
      "и\n",
      "учителей\n",
      "средний\n",
      ".\n",
      "школы\n",
      "/\n",
      "Под\n",
      "редакция\n",
      ".\n",
      "В.Ф. Киприянова\n",
      ".\n",
      "–\n",
      "Владимир\n",
      ",\n",
      "1977\n",
      ".\n",
      "–\n",
      "122\n",
      "секунда,страница\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# статистика по тексту\n",
    "txt = \"Виды лингвистического анализа: Учеб. пособие для студентов ф-та рус. яз. и лит. пед. ин-тов и учителей сред. школы / Под ред. В. Ф. Киприянова. – Владимир, 1977. – 122 с.\"\n",
    "tokenizer.process_(txt)\n",
    "tokenizer.postProcess()\n",
    "#print([t.txt for t in tokenizer.Promts[0].Grafems])\n",
    "# раскрыть все сокращения в тексте\n",
    "for prm in tokenizer.Promts:\n",
    "    for tok in prm.Grafems:\n",
    "        if 'СОК' in tok.tip:\n",
    "            if tokenizer.Sokr.findSocr(tok.txt) != \"\":\n",
    "                print(tokenizer.Sokr.findSocr(tok.txt).full)\n",
    "        else: print(tok.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e623e-98a9-4147-b17b-c66602a1af10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38torch",
   "language": "python",
   "name": "py38torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
